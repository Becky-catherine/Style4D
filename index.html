
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Style4D-Bench</title>

    <meta name="description" content="Project page for Style4D-Bench: A Benchmark Suite for 4D Stylization">
    <meta name="viewport" content="width=device-width, initial-scale=1">

         <!--FACEBOOK-->
    <meta property="og:image" content="img/teaser.jpg">
    <meta property="og:image:type" content="image/jpg">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://github.com/Becky-catherine/Style4D.github.io/"/>
    <meta property="og:title" content="Style4D-Bench" />
    <meta property="og:description" content="Project page for Style4D-Bench: A Benchmark Suite for 4D Stylization" />

     <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SparseNeRF" />
    <meta name="twitter:description" content="Project page for SparseNeRF: Distilling Depth Ranking for Few-shot Novel View Synthesis" />
    <meta name="twitter:image" content="img/teaser.jpg" />

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="../../stylesheet.css">
    <!-- <link rel="stylesheet" href="css/bootstrap.min.css"> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script type="text/javascript">
        function toggle_visibility(id) {
           var e = document.getElementById(id);
           if(e.style.display == 'block')
              e.style.display = 'none';
           else
              e.style.display = 'block';
        }
        </script>
</head>

<body>
    <script type="importmap">
        {
            "imports": {
                "three": "./js/three.module.js"
            }
        }
    </script>
    <script type="module" src='js/renderer.js'></script>
    <!-- The Modal -->
    <div id="myModal" class="modal">
        <!-- Modal content -->
        <div class="modal-content">
            <!-- <span class="close">&times;</span> -->
            <div class="row" style="align-content: center; width: 100%;">
                <div class="col-lg-8" style='padding-right:5px; padding-left:0px; '>
                    <div id="pano-container" style='text-align: center; height: 100%;'>
                        <img id="pano-img" src="" style="display: none;">
                    </div>
                </div>
                <div class="col-lg-4" style='padding-left:5px; padding-right:0px; height: 100%;'>
                    <div id="threejs-dynamic-container" style='text-align: center; height: 100%;'>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="container" id="main" style="width: 100%; max-width: 1500px;">
        <div class="row">
            <h1 class="col-md-12 text-center">
                <b> Style4D-Bench</b>: A Benchmark Suite for 4D Stylization <br>
                <small>
<!--                     NIPS 2025 -->
                </small>
            </h1>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="">
                            Beiqi Chen
                        </a><sup>*1,2</sup>&emsp;
                    </li>
                    <li>
                        <a href="">
                            Shuai Shao
                        </a><sup>*2</sup>&emsp;
                    </li>    
                    <li>
                        <a href="">
                           Haitang Feng
                        </a><sup>3,2</sup>&emsp;
                    </li>    
                    <li>
                        <a href="https://cse.sysu.edu.cn/teacher/LaiJianhuang">
                           Jianhuang Lai
                        </a><sup>4</sup>&emsp;
                    </li>  
                    <li>
                        <a href="">
                           Jianlou Si
                        </a><sup>5</sup><sup>†</sup>&emsp;
                    </li>                     
                    <li>
                        <a href="https://wanggcong.github.io/">
                            Guangcong Wang
                        </a><sup>2</sup><sup>†</sup><br>
                    </li>
<!--                     </br>Nanyang Technological University -->
                </ul>
            </div>
        </div>
        <div align="center">
            <sup>1</sup>Harbin Institute of Technology&emsp;
            <sup>2</sup>Vision, Graphics, and X Group, Great Bay University<br>
            <sup>3</sup>Nanjing University&emsp;
            <sup>4</sup>Sun Yat-Sen University&emsp;
            <sup>5</sup>Alibaba Group
        </div>
        <div align="center">
            <sup>*</sup>Equal Contribution&nbsp;&nbsp;&nbsp;&nbsp;
            <sup>†</sup>Corresponding Authors
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2303.16196">
                            <image src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01-p-500.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/Tf6QnksXFxQ">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/Becky-catherine/Style4D-Bench">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
<!--                         <li>
                            <a href="https://docs.google.com/presentation/d/1cEhC97jnLvVDyh33q-vRo_5Ook0y8mTV/edit?usp=sharing&ouid=115205863499027963192&rtpof=true&sd=true">
                            <image src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01-p-500.png" height="60px">
                                <h4><strong>Poster</strong></h4>
                            </a>
                        </li> -->
                        
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
<!--                 <p class="text-justify">
                <strong>TL;DR:</strong> We present Style4D, a new framework for stylizing dynamic 4D scenes, preserving both temporal and multi-view consistency.
                </p> -->
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/mission.mp4" type="video/mp4"/>
                </video>
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    We introduce Style4D-Bench, the first benchmark suite specifically designed for 4D stylization, with the goal of standardizing evaluation and facilitating progress in this emerging area. Style4D-Bench comprises: 1) a strong baseline that make an initial attempt for 4D stylization, 2) a comprehensive evaluation protocol measuring spatial fidelity, temporal coherence, and multi-view consistency through both perceptual and quantitative metrics, and 3) a curated collection of high-resolution dynamic 4D scenes with diverse motions and complex backgrounds. To establish a strong baseline, we present Style4D, a novel framework built upon 4D Gaussian Splatting. It consists of three key components: a basic 4DGS scene representation to capture reliable geometry, a Style Gaussian Representation that leverages lightweight per-Gaussian MLPs for temporally and spatially aware appearance control, and a Holistic Geometry-Preserved Style Transfer module designed to enhance spatio-temporal consistency via contrastive coherence learning and structural content preservation. Extensive experiments on Style4D-Bench demonstrate that Style4D achieves state-of-the-art performance in 4D stylization, producing fine-grained stylistic details with stable temporal dynamics and consistent multi-view rendering. We expect Style4D-Bench to become a valuable resource for benchmarking and advancing research in stylized rendering of dynamic 3D scenes.
                </p>
            </div>
        </div>

        <div class="row">
<!--             可增加动机 -->
<!--             <div class="col-md-8 col-md-offset-2">
                <h3>
                    Motivation
                </h3>
                <br>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/demo_video_v8_motivation.mp4" type="video/mp4"/>
                </video>
                <p class="text-justify">
                    Depth maps are coarse: (a) inconsistent 3D geometry; (b) and (c) time jittering; (d) scale-invariant error. Directly scaling the coarse depth maps to a NeRF leads to inconsistent geometry against the expected depth of the NeRF. Instead of directly supervising a NeRF with coarse depth priors, we relax hard depth constraints and distill robust local depth ranking from the coarse depth maps to a NeRF such that the depth ranking of a NeRF is consistent with that of coarse depth. That is, we supervise a NeRF with relative depth instead of absolute depth.
               </p>
            </div> -->
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p style="text-align:center;">
                    <image src="img/metric_pic.png" class="img-responsive" alt="scales">
                </p>
            </div>
        </div>    
    
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Framework
                </h3>
                <p style="text-align:center;">
                    <image src="img/framework.png" class="img-responsive" alt="scales">
                </p>
                <p class="text-justify">
                    Framework Overview: Style4D consists of three key components, a basic 4DGS representation, a Style Gaussian Representation, and a Holistic Geometry-preserved Style Transfer. We first train a basic 4DGS representation with the content image to obtain 4D scene geometry. Then we propose a new Style Gaussian Representation for 4D stylization. We also introduce a Holistic Geometry-preserved Style Transfer module to improve consistency and quality of stylization.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Demo Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Tf6QnksXFxQ?si=HBLQqcwrXWQ-BU-p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>

                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results: more stylized results
                </h3>
                <br>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/demo_more.mp4" type="video/mp4"/>
                </video>
            </div>
        </div>

    
    
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10" style="padding: 0%; margin: 0%;">
                    <textarea id="bibtex" class="form-control" readonly>
@misc{chen2025style4dbenchbenchmarksuite4d,
      title={Style4D-Bench: A Benchmark Suite for 4D Stylization}, 
      author={Beiqi Chen and Shuai Shao and Haitang Feng and Jianhuang Lai and Jianlou Si and Guangcong Wang},
      year={2025},
      eprint={2508.19243},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.19243}, 
}
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related Links
                </h3>
                <p class="text-justify">
                    <a href="https://scene-dreamer.github.io/">SceneDreamer</a>: Unbounded 3D Scene Generation from 2D Image Collections. <br>
                    <a href="https://classifier-as-generator.github.io/">CaG</a>: Traditional Classification Neural Networks are Good Generators: They are Competitive with DDPMs and GANs.<br>
                    <a href="https://frozenburning.github.io/projects/text2light/">Text2light</a>: Zero-Shot Text-Driven HDR Panorama Generation. <br>
                    <a href="https://style-light.github.io/">StyleLight</a> generates HDR indoor panorama from a limited FOV image. <br>
                    <a href="https://fast-vid2vid.github.io/">Fast-Vid2Vid</a>: Spatial-Temporal Compression for Video-to-Video Synthesis. <br>
                    <a href="https://hongfz16.github.io/projects/AvatarCLIP.html">AvatarCLIP</a> proposes a zero-shot text-driven framework for 3D avatar generation and animation. <br>
                    <a href="https://yumingj.github.io/projects/Text2Human.html">Text2Human</a> proposes a text-driven controllable human image generation framework. <br>
                    <a href="https://frozenburning.github.io/projects/relighting4d/">Relighting4D</a> can relight human actors using the HDRI generated by us. <br>
                </p>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The computational resources are supported by SongShan Lake HPC Center (SSL-HPC) in Great Bay University. This work was also supported by Guangdong Research Team for Communication and Sensing Integrated with Intelligent Computing (Project No. 2024KCXTD047).
                    <br>
                    <br>


                The website template is borrowed from <a href="https://sparsenerf.github.io/">SparseNeRF</a>.
                </p>
                <br>
            </div>
        </div>

         

    
    <!-- this is comment-->
            

    <!-- <div class="section" style="width:200px; margin-left: 40%;">  -->
    <div class="section" style="text-align:center; padding:0 0 20px 0">
        <a href="https://clustrmaps.com/site/1c6m7"  title="ClustrMaps"><img src="//www.clustrmaps.com/map_v2.png?d=R6omcJIZQKvI02heb0DO4AWuoeBEIrySs3zSmBj72gg&cl=ffffff" /></a>
    </div>


            
  </div> <!-- #content -->           
                    
  </div>
</body>

</html>
